{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Lesson_3_lesson_concepts.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anhle/AI-Healthcare/blob/master/AI_EHR/Ex/Lesson_3_lesson_concepts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMuFPYQqfu81",
        "colab_type": "text"
      },
      "source": [
        "This the code for walking through the lesson examples for your reference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l7UqIePfu83",
        "colab_type": "text"
      },
      "source": [
        "## Code for Building Synthetic Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNt59-iafu83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPlx7M7Lfu87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#build synthetic line level example\n",
        "NUMBER_RECORDS = 100000\n",
        "NUMBER_ENCOUNTERS = 7800\n",
        "NUMBER_PATIENTS = 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sar1mS-Hfu89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create random list of code sets for diagnosis, procedure, medication, and lab codes\n",
        "dx_code_list = [\"dx_code_\" + str(x) for x in np.arange(1,100000)]\n",
        "procedure_code_list =[\"procedure_code_\" + str(x) for x in np.arange(0,73000)]\n",
        "medication_code_list = [\"medication_code_\" + str(x) for x in np.arange(0,10000)]\n",
        "lab_code_list = [\"lab_code_\" + str(x) for x in np.arange(0,10000)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1-gMDXkfu9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "patient_id_list = [\"udacity_health_patient_id_\" + str(x) for x in np.arange(1, NUMBER_PATIENTS +1)]\n",
        "encounter_id_list = [\"udacity_health_encounter_id_\" + str(x) for x in np.arange(1, NUMBER_ENCOUNTERS +1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oe9iSjkfu9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_value_selection(field_value_list, number_records):\n",
        "    #build normal probability distribution \n",
        "    field_prob_dist = np.random.dirichlet(np.ones(len(field_value_list)), size=1)[0] \n",
        "    #build random value list for field\n",
        "    field_random_values = np.random.choice(field_value_list, number_records, p=field_prob_dist)\n",
        "    return field_random_values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoiuWlvqfu9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#patient_values = random_value_selection(patient_id_list, NUMBER_RECORDS)\n",
        "encounter_values = random_value_selection(encounter_id_list, NUMBER_RECORDS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdH8iAVAfu9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encounter_patient_mapping = dict(zip(encounter_id_list,   random_value_selection(patient_id_list, NUMBER_ENCOUNTERS)))\n",
        "patient_values = [encounter_patient_mapping[x] for x in encounter_values]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAp_GMoyfu9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dx_value_mapping = dict(zip(encounter_id_list, random_value_selection(dx_code_list, NUMBER_ENCOUNTERS) ))\n",
        "dx_values = [dx_value_mapping[x] for x in encounter_values ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-k2I1tbfu9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "procedure_values = random_value_selection(procedure_code_list, NUMBER_RECORDS)\n",
        "medication_values = random_value_selection(medication_code_list, NUMBER_RECORDS)\n",
        "lab_values = random_value_selection(lab_code_list, NUMBER_RECORDS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYtyLn4zfu9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "triplet_prob_choice = np.random.choice([0, 1, 2], NUMBER_RECORDS, p= np.random.dirichlet(np.ones(3), size=1)[0] )\n",
        "line_triplet_values = list(zip(procedure_values, medication_values, lab_values, triplet_prob_choice))\n",
        "selected_procedure_values = [x[0] if x[3] == 0 else np.nan for x in line_triplet_values ]\n",
        "selected_medication_values = [x[1] if x[3] == 1 else np.nan for x in line_triplet_values]\n",
        "selected_lab_values = [x[2] if x[3] == 2 else np.nan for x in line_triplet_values]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnAuqOpfu9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#add label\n",
        "patient_label_mapping = dict(zip( patient_id_list, np.random.choice([0, 1], NUMBER_PATIENTS, replace=True, \n",
        "                                                                    p=[0.88, 0.12]) ))\n",
        "label_values = [patient_label_mapping[x] for x in patient_values]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bAhMgN2fu9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "line_df = pd.DataFrame({ \"ENCOUNTER_ID\": encounter_values,\n",
        "                        \"PATIENT_ID\": patient_values,\n",
        "                        \"PRINCIPAL_DIAGNOSIS_CODE\": dx_values,\n",
        "                        \"PROCEDURE_CODE\": selected_procedure_values,\n",
        "                        \"MEDICATION_CODE\": selected_medication_values,\n",
        "                        \"LAB_CODE\": selected_lab_values,\n",
        "                        \"LABEL\": label_values\n",
        "                       })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov_GXO7xfu9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#line_df.to_csv(\"./data/SYNTHETIC_EHR_DATASET.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SU7IAoFRfu9a",
        "colab_type": "text"
      },
      "source": [
        "## 1. Converting Line to Encounter Representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6bluEvmfu9a",
        "colab_type": "text"
      },
      "source": [
        "### Load Synthetic EHR Line Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzWdf0c0fu9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ehr_line_df = pd.read_csv(\"https://raw.githubusercontent.com/anhle/AI-Healthcare/master/AI_EHR/Ex/data/SYNTHETIC_EHR_DATASET.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7_oLhLpfu9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ehr_line_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxPTLMjdfu9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ehr_line_df[ehr_line_df['ENCOUNTER_ID']=='udacity_health_encounter_id_100']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOryaDcTfu9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#note that this is for illustrative purposes only and for practicing key skills, \n",
        "# the actual data representation and combinations of codes not indicative of real thing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59_8bqIRfu9l",
        "colab_type": "text"
      },
      "source": [
        "### Convert Line to Encounter Representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PE7L8lAfu9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# grouping fields \n",
        "grouping_field_list = ['ENCOUNTER_ID', 'PATIENT_ID', 'PRINCIPAL_DIAGNOSIS_CODE']\n",
        "non_grouped_field_list = [c for c in ehr_line_df.columns if c not in grouping_field_list]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVKhvZn8ip3Q",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTbylKE4ip_V",
        "colab_type": "text"
      },
      "source": [
        "Create a new dataframe that groups the data by \"patient_id\". Again you can use groupby() and agg() methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKFFvYXVfu9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encounter_df = ehr_line_df.groupby(grouping_field_list)[non_grouped_field_list].agg(lambda x: \n",
        "                                                        list([y for y in x if y is not np.nan ] ) ).reset_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qCuRBeOfu9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encounter_df[0:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQy1VsKWi3EC",
        "colab_type": "text"
      },
      "source": [
        "Inspect and compare the data again by selecting a single patient and compare the \"encounter\", \"principal_diagnosis\", and \"procedure_codes\". You should see all of these codes represented in arrays/lists for each patient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCpF0zI4fu9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ehr_line_df[ehr_line_df['ENCOUNTER_ID']=='udacity_health_encounter_id_1']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJTaBMdRfu9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encounter_df[encounter_df['ENCOUNTER_ID']=='udacity_health_encounter_id_1']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgHWVMIvfu90",
        "colab_type": "text"
      },
      "source": [
        "## 2. Converting Encounter to Longitudinal Representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20rl-WnGfu90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encounter_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWW1yeMWfu92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "patient_grouping_field_list = [\"PATIENT_ID\"]\n",
        "non_patient_agg_field_list = [c for c in encounter_df.columns if c not in patient_grouping_field_list]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSubeiBefu94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "long_df = encounter_df.groupby(patient_grouping_field_list)[non_patient_agg_field_list].agg(lambda x: \n",
        "                                                        list([y for y in x if y is not np.nan ] ) ).reset_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofCMRgvkfu97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "long_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCvK7pUvfu99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example_patient_history = long_df[long_df['PATIENT_ID']=='udacity_health_patient_id_310']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9JQIa9Ufu9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example_patient_history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FyRQt2Cfu-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(example_patient_history['ENCOUNTER_ID'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBMM5Noyfu-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(example_patient_history['PRINCIPAL_DIAGNOSIS_CODE'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQwfSh0_fu-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(example_patient_history['PROCEDURE_CODE'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6non7Jxfu-H",
        "colab_type": "text"
      },
      "source": [
        "## 3. How to Split Dataset at Patient Level"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls-_AeJafu-H",
        "colab_type": "text"
      },
      "source": [
        "#### ***Objective:*** \n",
        "- Split dataset at patient level into train and test partitions\n",
        "- Validate that split was done correctly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pP9_PqC-fu-I",
        "colab_type": "text"
      },
      "source": [
        "#### Dataset Splitting Tests\n",
        "- Patient data in only one partition\n",
        "- Total unique number of patients across all partitions = total number unique patients in original full dataset\n",
        "- Total number of rows original dataset = sum of rows across splits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzQFaW9sfu-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATIENT_ID_FIELD = 'PATIENT_ID'\n",
        "TEST_PERCENTAGE = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj47C0xLfu-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_dataset_patient_level(df, key, test_percentage=0.2):\n",
        "    df = df.iloc[np.random.permutation(len(df))]\n",
        "    unique_values = df[key].unique()\n",
        "    total_values = len(unique_values)\n",
        "    sample_size = round(total_values * (1 - test_percentage ))\n",
        "    train = df[df[key].isin(unique_values[:sample_size])].reset_index(drop=True)\n",
        "    test = df[df[key].isin(unique_values[sample_size:])].reset_index(drop=True)\n",
        "    return train, test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEiJe_P1fu-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df, test_df = split_dataset_patient_level(encounter_df, PATIENT_ID_FIELD, TEST_PERCENTAGE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYtvc_zffu-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert len(set(train_df[PATIENT_ID_FIELD].unique()).intersection(set(test_df[PATIENT_ID_FIELD].unique()))) == 0\n",
        "print(\"Test passed for patient data in only one partition\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-5aJ_FXfu-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert (train_df[PATIENT_ID_FIELD].nunique()  + test_df[PATIENT_ID_FIELD].nunique()) == encounter_df[PATIENT_ID_FIELD].nunique()\n",
        "print(\"Test passed for number of unique patients being equal!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkR_NbhBfu-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert len(train_df)  + len(test_df) == len(encounter_df)\n",
        "print(\"Test passed for number of total rows equal!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWzEk3eJfu-U",
        "colab_type": "text"
      },
      "source": [
        "## 4. ETL with TF Dataset API and Pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zar-N987fu-U",
        "colab_type": "text"
      },
      "source": [
        "NOTE: In some cases you may need to preprocess Pandas Dataframe to removed mixed types. In particular, remove null values and impute or remove rows (we will later impute with zero for numerical features)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpQOgpEAfu-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogOAMMuzfu-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "swiss_dataset_path = \"./data/processed_swiss.csv\"\n",
        "swiss_df = pd.read_csv(swiss_dataset_path)\n",
        "selected_col_list = ['age', 'thalach', 'cp', 'num_label']\n",
        "subset_swiss_df = swiss_df[selected_col_list]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZOTP78efu-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "swiss_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdtTEAXlfu-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subset_swiss_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98PiHt5Lfu-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#adapted from https://www.tensorflow.org/tutorials/structured_data/feature_columns\n",
        "def df_to_dataset(df, predictor,  batch_size=32):\n",
        "    df = df.copy()\n",
        "    labels = df.pop(predictor)\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
        "    ds = ds.shuffle(buffer_size=len(df))\n",
        "    ds = ds.batch(batch_size)\n",
        "    return ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmnITGTCfu-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "PREDICTOR_FIELD = 'num_label'\n",
        "sample_tf_ds = df_to_dataset(subset_swiss_df, PREDICTOR_FIELD, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXE4XLtCfu-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_feature_batch = next(iter(sample_tf_ds))[0]\n",
        "sample_feature_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sASVmHt7fu-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_label_batch = next(iter(sample_tf_ds))[1]\n",
        "sample_label_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-E_P9G8fu-o",
        "colab_type": "text"
      },
      "source": [
        "## 5. Building Numerical Feature with TF Feature Column API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM2IgGy6fu-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subset_swiss_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOBeSR-afu-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "age_mean = subset_swiss_df['age'].describe()['mean']\n",
        "age_std = subset_swiss_df['age'].describe()['std']\n",
        "print(\"Mean age:{}\\nStandard Deviation Age:{}\".format(age_mean, age_std))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MonGv8sfu-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import functools\n",
        "def normalize_numeric_with_zscore(col, mean, std):\n",
        "    return (col - mean)/std\n",
        "\n",
        "def create_tf_numeric_feature(col, MEAN, STD,   default_value=0):\n",
        "    normalizer = functools.partial(normalize_numeric_with_zscore, mean=MEAN, std=STD)\n",
        "    return tf.feature_column.numeric_column(\n",
        "    key=col, default_value = default_value, normalizer_fn=normalizer, dtype=tf.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHTIpNf2fu-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "age_tf_feature = create_tf_numeric_feature('age', age_mean, age_std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7tnB5-ofu-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def demo(feature_column, example_batch):\n",
        "    feature_layer = tf.keras.layers.DenseFeatures(feature_column)\n",
        "    print(feature_layer(example_batch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnEeqdkbfu-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Example continuous field:\\n{}\\n\".format(age_tf_feature))\n",
        "demo(age_tf_feature, sample_feature_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3MTsssNfu-2",
        "colab_type": "text"
      },
      "source": [
        "## 6. Building Categorical Features with TF Feature Column API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VXzJvQkfu-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categorical_example_df = encounter_df[['ENCOUNTER_ID', 'PRINCIPAL_DIAGNOSIS_CODE', 'LABEL']] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrucVuLJfu-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for this task need to convert label from array to scalar value\n",
        "categorical_example_df['LABEL'] = categorical_example_df['LABEL'].apply(lambda x: np.unique(x)[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaJB5gfifu-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categorical_example_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWOf5TKUfu-9",
        "colab_type": "text"
      },
      "source": [
        "### High Cardinality for Principal Diagnosis Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLoQPbqkfu-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categorical_example_df['PRINCIPAL_DIAGNOSIS_CODE'].nunique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chXMpK8Hfu-_",
        "colab_type": "text"
      },
      "source": [
        "### Generate Vocabulary File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr28SilNfu-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#make vocab dir\n",
        "import os\n",
        "#os.mkdir(\"./vocab/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9n_pdEIfu_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build vocab for categorical features\n",
        "def write_vocabulary_file(vocab_list, field_name, default_value, vocab_dir='./vocab/'):\n",
        "    output_file_path = os.path.join(vocab_dir, str(field_name) + \"_vocab.txt\")\n",
        "    # put default value in first row as TF requires\n",
        "    vocab_list = np.insert(vocab_list, 0, default_value, axis=0) \n",
        "    df = pd.DataFrame(vocab_list).to_csv(output_file_path, index=None, header=None)\n",
        "    return output_file_path\n",
        "\n",
        "def build_vocab_files(df, categorical_column_list, default_value='00'):\n",
        "    vocab_files_list = []\n",
        "    for c in categorical_column_list:\n",
        "        v_file = write_vocabulary_file(df[c].unique(), c, default_value)\n",
        "        vocab_files_list.append(v_file)\n",
        "    return vocab_files_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQAFb7rHfu_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categorical_field_list = [\"PRINCIPAL_DIAGNOSIS_CODE\"]\n",
        "vocab_files_list = build_vocab_files(categorical_example_df, categorical_field_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIYWKqtjfu_G",
        "colab_type": "text"
      },
      "source": [
        "### Build TF Dataset from Pandas Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6mq_M95fu_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "PREDICTOR_FIELD = 'LABEL'\n",
        "categorical_tf_ds = df_to_dataset(categorical_example_df, PREDICTOR_FIELD, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vay4yBdWfu_I",
        "colab_type": "text"
      },
      "source": [
        "### Use TF Feature Column API to read from vocab file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7PGi2dcfu_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_files_list[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOmRLEeJfu_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "principal_diagnosis_vocab = tf.feature_column.categorical_column_with_vocabulary_file(\n",
        "            key=\"PRINCIPAL_DIAGNOSIS_CODE\", vocabulary_file = vocab_files_list[0], num_oov_buckets=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNWg3x5Tfu_L",
        "colab_type": "text"
      },
      "source": [
        "### Create one-hot encoding  from vocab column feature function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jhq_wp5fu_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_hot_principal_diagnosis_feature = tf.feature_column.indicator_column(principal_diagnosis_vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C19MA_Szfu_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categorical_tf_ds_batch = next(iter(categorical_tf_ds))[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK_bj1PAfu_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "demo(one_hot_principal_diagnosis_feature, categorical_tf_ds_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj_LhfnRfu_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbDfkbZFfu_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}